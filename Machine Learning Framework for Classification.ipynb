{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os import listdir\n",
    "plt.rcParams['figure.figsize'] = (10, 3) # set default size of plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks\n",
    "from imblearn.over_sampling import SMOTE, ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read X and y\n",
    "# X = ...\n",
    "# y = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale and Smote\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns = X.columns)\n",
    "\n",
    "# Sampling\n",
    "sampler = SMOTE(ratio='minority')\n",
    "X_sampled, y = sampler.fit_resample(X, y)\n",
    "X = pd.DataFrame(X_sampled, columns = X.columns) #XGBoost algorithm raises error without that because RUS returns a numpy array with no column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Random Forest\n",
    "n_estimators = [100, 250]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [3, 5,  9]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 3, 5]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "criterion = ['gini', 'entropy']\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "            'max_features': max_features,\n",
    "            'max_depth': max_depth,\n",
    "            'min_samples_split': min_samples_split,\n",
    "            'min_samples_leaf': min_samples_leaf,\n",
    "            'bootstrap': bootstrap,\n",
    "            'criterion': criterion}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf_grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 5, n_jobs = 3, verbose=1, scoring = \"f1\")\n",
    "rf_grid_search.fit(X, y)\n",
    "print(rf_grid_search.best_params_)\n",
    "print(\"Score: \", rf_grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "grid_xgb = {'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2],\n",
    "        'subsample': [0.7, 1.0],\n",
    "        'colsample_bytree': [0.7, 1.0],\n",
    "        'max_depth': [3, 5, 9]}\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb_grid_search = GridSearchCV(xgb, grid_xgb, cv=5, n_jobs= 3, verbose = 1, scoring = \"f1\")\n",
    "xgb_grid_search.fit(X,y)\n",
    "print(\"Score: \",xgb_grid_search.best_score_)\n",
    "print(xgb_grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM\n",
    "lgbm = lgb.LGBMClassifier(silent=False)\n",
    "param_grid = {\"max_depth\": [3, 5, 9,], \"learning_rate\" : [0.008, 0.01, 0.012], \n",
    "              \"num_leaves\": [80, 120], \"n_estimators\": [200, 250]}\n",
    "lgbm_grid_search = GridSearchCV(lgbm, param_grid, cv=5, refit=True, n_jobs = 3, verbose=1,  scoring = \"f1\")\n",
    "lgbm_grid_search.fit(X,y)\n",
    "print(lgbm_grid_search.best_params_)\n",
    "print(\"Score: \", lgbm_grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP\n",
    "mlp =  MLPClassifier()\n",
    "param_grid={\n",
    "'learning_rate': (\"constant\", \"invscaling\", \"adaptive\"),\n",
    "'hidden_layer_sizes': ((X.shape[1], X.shape[1]),\n",
    "                       (X.shape[1]* 2, X.shape[1], X.shape[1] // 2),\n",
    "                       (int(X.shape[1]*1.5)//1, X.shape[1]*2, int(X.shape[1]*1.5)//1)),\n",
    "'alpha': (10.0 ** -np.arange(1, 7)),\n",
    "'activation': [(\"relu\")]}\n",
    "mlp_grid_search = GridSearchCV(mlp, param_grid, cv=5, refit=True, n_jobs = 3, verbose=1,  scoring = \"f1\")\n",
    "mlp_grid_search.fit(X,y)\n",
    "print(mlp_grid_search.best_params_)\n",
    "print(\"Score: \", mlp_grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier(n_jobs = -1)# n_estimators = 250, min_samples_split = 2, min_samples_leaf = 2, max_features = 'sqrt', max_depth = 10, bootstrap = True)\n",
    "clf_xgb = XGBClassifier(n_jobs = -1,probability = True) # colsample_bytree = 0.6, gamma=1, max_depth=9, min_child_weight=1,subsample=1, probability = True)\n",
    "clf_lgbm = lgb.LGBMClassifier(n_jobs = -1,silent = True) # learning_rate= 0.012, max_depth = 10, n_estimators =  250, num_leaves= 80, silent=True, probability = True)\n",
    "clf_mlp = MLPClassifier()\n",
    "\n",
    "clf_rf.set_params(**rf_grid_search.best_params_)\n",
    "clf_xgb.set_params(**xgb_grid_search.best_params_)\n",
    "clf_lgbm.set_params(**lgbm_grid_search.best_params_)\n",
    "clf_mlp.set_params(**mlp_grid_search.best_params_)\n",
    "\n",
    "classifiers = [clf_rf, clf_xgb, clf_lgbm, clf_mlp]\n",
    "clf_list=[]\n",
    "for clf in classifiers:\n",
    "    clf_list.append(clf.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "setparams = True\n",
    "clf_rf = RandomForestClassifier(n_estimators = 250, n_jobs = -1)\n",
    "\n",
    "clf_xgb = XGBClassifier(nthread = -1)\n",
    "\n",
    "clf_lgbm = lgb.LGBMClassifier(n_estimators = 250,\n",
    "                              silent=True, probability = True)\n",
    "\n",
    "clf_mlp = MLPClassifier(hidden_layer_sizes = (int((X.shape[1]* 1.5)//1), X.shape[1]*2, int((X.shape[1]*1.5)//1)),\n",
    "                        activation = 'relu',)\n",
    "\n",
    "# Set Hyperparameters\n",
    "if setparams == True:\n",
    "    clf_rf.set_params(**rf_grid_search.best_params_)\n",
    "    clf_xgb.set_params(**xgb_grid_search.best_params_)\n",
    "    clf_lgbm.set_params(**lgbm_grid_search.best_params_)\n",
    "    clf_mlp.set_params(**mlp_grid_search.best_params_)\n",
    "\n",
    "my_metrics = ['Accuracy_dict','BalancedAccuracy_dict', 'Recall_dict', 'Precision_dict', 'Fscore_dict']\n",
    "scaler = StandardScaler()\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 5, random_state=None, shuffle=False)\n",
    "Accuracy_dict = {}\n",
    "BalancedAccuracy_dict = {}\n",
    "Recall_dict = {}\n",
    "Precision_dict = {}\n",
    "Fscore_dict = {}\n",
    "clf_list=[]\n",
    "conf_rf = np.zeros([2,2])\n",
    "conf_xgb = np.zeros([2,2])\n",
    "conf_lgbm = np.zeros([2,2])\n",
    "conf_mlp = np.zeros([2,2])\n",
    "conf_eclf = np.zeros([2,2])\n",
    "\n",
    "pred_dict = pd.DataFrame(columns = clf_list)\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf_list.append(clf.__class__.__name__)\n",
    "\n",
    "stacked_results = pd.DataFrame()\n",
    "stacked_probabilities = pd.DataFrame()\n",
    "final_ensembled_metrics = pd.Series(np.zeros([1,len(my_metrics)])[0])\n",
    "final_probs = pd.DataFrame()\n",
    "aggregated_y_test = []\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Scaling\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # PCA\n",
    "    #pca = PCA(n_components = n_of_components)\n",
    "    #pca.fit(X_train)\n",
    "    #X_train = pca.transform(X_train)\n",
    "    #X_test = pca.transform(X_test)\n",
    "\n",
    "    # Sampling\n",
    "    sampler = SMOTE(sampling_strategy = 'minority') # Synthetic Minority Over Sampling Technique\n",
    "    X_train, y_train = sampler.fit_sample(X_train, y_train)\n",
    "\n",
    "    a = pd.DataFrame()\n",
    "    b = pd.DataFrame()\n",
    "    for clf in classifiers:\n",
    "        name = clf.__class__.__name__\n",
    "        clf.fit(X_train, y_train)\n",
    "        train_predictions = pd.Series(clf.predict(X_test))\n",
    "        train_probabilities = pd.Series(clf.predict_proba(X_test)[:,1])\n",
    "        Accuracy = metrics.accuracy_score(y_test, train_predictions)\n",
    "        BalancedAccuracy = metrics.balanced_accuracy_score(y_test, train_predictions)\n",
    "        Recall = metrics.recall_score(y_test, train_predictions)\n",
    "        Precision = metrics.precision_score(y_test, train_predictions)\n",
    "        Fscore = metrics.f1_score(y_test, train_predictions)\n",
    "\n",
    "        if clf == clf_rf:\n",
    "            conf_rf += metrics.confusion_matrix(y_test, train_predictions)\n",
    "        if clf == clf_xgb:\n",
    "            conf_xgb += metrics.confusion_matrix(y_test, train_predictions)\n",
    "        if clf == clf_lgbm:\n",
    "            conf_lgbm += metrics.confusion_matrix(y_test, train_predictions)\n",
    "        if clf == clf_mlp:\n",
    "            conf_mlp += metrics.confusion_matrix(y_test, train_predictions)\n",
    "\n",
    "\n",
    "        for x in my_metrics:\n",
    "            if name in eval(x):\n",
    "                eval(x)[name] += eval(x.split(\"_\")[0])\n",
    "            else:\n",
    "                eval(x)[name] = eval(x.split(\"_\")[0])\n",
    "        a = pd.concat([a, train_predictions], axis=1)\n",
    "        b = pd.concat([b, train_probabilities], axis=1)\n",
    "    \n",
    "    probs = pd.DataFrame(b.mean(axis=1))\n",
    "    \n",
    "    final_probs = pd.concat([final_probs, b], axis = 0)\n",
    "    aggregated_y_test = np.concatenate((aggregated_y_test, y_test.values))\n",
    "    probs[probs[0] < 0.5] = 0\n",
    "    probs[probs[0] >= 0.5] = 1\n",
    "    ensembled_preds = probs\n",
    "    conf_eclf += metrics.confusion_matrix(y_test, ensembled_preds)\n",
    "    ensembled_metrics = []\n",
    "    ensembled_metrics.append(metrics.accuracy_score(y_test, ensembled_preds))\n",
    "    ensembled_metrics.append(metrics.balanced_accuracy_score(y_test, ensembled_preds))\n",
    "    ensembled_metrics.append(metrics.recall_score(y_test, ensembled_preds))\n",
    "    ensembled_metrics.append(metrics.precision_score(y_test, ensembled_preds))\n",
    "    ensembled_metrics.append(metrics.f1_score(y_test, ensembled_preds))\n",
    "    final_ensembled_metrics += pd.Series(ensembled_metrics)\n",
    "\n",
    "    stacked_results = pd.concat([stacked_results,a], axis = 0)\n",
    "stacked_results.columns = clf_list\n",
    "\n",
    "final_probs['GT'] = aggregated_y_test\n",
    "clf_list.append('GT')\n",
    "final_probs.columns = clf_list\n",
    "final_probs = final_probs.round(2)\n",
    "\n",
    "metric_results = pd.DataFrame()\n",
    "for x in my_metrics:\n",
    "    metric_results = metric_results.append(pd.DataFrame(data = [list((eval(x).values()))] , columns = list((eval(x).keys()))))\n",
    "metric_results.index = [\"Accuracy\", \"Bal_Accuracy\", \"Recall\", \"Precision\", \"Fscore\"]\n",
    "metric_results['EnsembledClassifiers'] = list(final_ensembled_metrics)\n",
    "metric_results = metric_results.T/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Bal_Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Fscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.947719</td>\n",
       "      <td>0.526202</td>\n",
       "      <td>0.075486</td>\n",
       "      <td>0.100455</td>\n",
       "      <td>0.085632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.886942</td>\n",
       "      <td>0.583175</td>\n",
       "      <td>0.258366</td>\n",
       "      <td>0.099792</td>\n",
       "      <td>0.140122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.954197</td>\n",
       "      <td>0.559260</td>\n",
       "      <td>0.136965</td>\n",
       "      <td>0.200442</td>\n",
       "      <td>0.161414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPClassifier</th>\n",
       "      <td>0.790421</td>\n",
       "      <td>0.564514</td>\n",
       "      <td>0.322957</td>\n",
       "      <td>0.071607</td>\n",
       "      <td>0.107795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EnsembledClassifiers</th>\n",
       "      <td>0.943610</td>\n",
       "      <td>0.566200</td>\n",
       "      <td>0.162646</td>\n",
       "      <td>0.162733</td>\n",
       "      <td>0.159680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Accuracy  Bal_Accuracy    Recall  Precision    Fscore\n",
       "RandomForestClassifier  0.947719      0.526202  0.075486   0.100455  0.085632\n",
       "XGBClassifier           0.886942      0.583175  0.258366   0.099792  0.140122\n",
       "LGBMClassifier          0.954197      0.559260  0.136965   0.200442  0.161414\n",
       "MLPClassifier           0.790421      0.564514  0.322957   0.071607  0.107795\n",
       "EnsembledClassifiers    0.943610      0.566200  0.162646   0.162733  0.159680"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
